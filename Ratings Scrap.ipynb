{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCRAPING DATA OF REVIEWS FROM AMAZON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating python program to search desired keywords one by one and saving links in open list prod_url\n",
    "\n",
    "# creating open list to save href links of all products \n",
    "prod_url = []\n",
    "\n",
    "# Keywords for search to which we need to scrape the data.\n",
    "keywords = ['Laptops', 'Phones', 'Headphones', 'Smart Watches', 'Cameras', 'Printers', 'Monitors','Home theater', 'Router']\n",
    "\n",
    "# Location of chrome web driver and launching it\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\") \n",
    "\n",
    "# website from which we will scrape data\n",
    "driver.get(\"https://www.amazon.in/\") \n",
    "\n",
    "initial_url = driver.current_url\n",
    "\n",
    "# loop for sending keywords to website and scraping href\n",
    "for i in keywords:\n",
    "    # Finding search input and giving input\n",
    "    search = driver.find_element_by_id(\"twotabsearchtextbox\").send_keys(i)\n",
    "        \n",
    "    # clicking on search button\n",
    "    search_btn = driver.find_element_by_xpath(\"//div[@class='nav-search-submit nav-sprite']\")\n",
    "    search_btn.click()\n",
    "    # giving time to load the webpage completely to avoid errors\n",
    "    time.sleep(5)\n",
    "    # finding href of each products mentioned in keywords\n",
    "    for j in driver.find_elements_by_xpath(\"//h2[@class = 'a-size-mini a-spacing-none a-color-base s-line-clamp-2']/a\"):\n",
    "        prod_url.append(j.get_attribute('href'))\n",
    "    # returning to initial url    \n",
    "    driver.get(initial_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking length of prod_url\n",
    "len(prod_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening each 226 prod_url and scraping links of all reviews href \n",
    "# open list to save all reviews href\n",
    "rev_cli = []\n",
    "\n",
    "# loop for opening all links stored in prod_url\n",
    "for j in prod_url:\n",
    "    # opening each links of prod_url one by one\n",
    "    driver.get(j)\n",
    "    \n",
    "    try:\n",
    "        # finding links from all webpage by xpath\n",
    "        for k in driver.find_elements_by_xpath(\"//a[@id = 'acrCustomerReviewLink']\"):\n",
    "            rev_cli.append(k.get_attribute('href'))\n",
    "    # if all reviews link is not available, it will continue to next page,so avoiding NoSuchElementException \n",
    "    except NoSuchElementException as e:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "455"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking length of open list\n",
    "len(rev_cli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now opening each links as stored in list above\n",
    "# creating open list for storing all reviews href\n",
    "all_reviews = []\n",
    "\n",
    "for l in rev_cli:\n",
    "    # opening each links as stored in cli_rev open list\n",
    "    driver.get(l)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    try:\n",
    "        # finding links from all webpage by xpath\n",
    "        all_rev = driver.find_element_by_xpath(\"//div[@id = 'reviews-medley-footer']/div[2]/a\")\n",
    "        all_reviews.append(all_rev.get_attribute('href'))\n",
    "        # if all reviews link is not available, it will continue to next page,so avoiding NoSuchElementException \n",
    "    except NoSuchElementException as e:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "451"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking length of all reviews link\n",
    "len(all_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally opening all_reviews link and scraping ratings and reviews data from all webpages.\n",
    "# creating open list to save scraped data\n",
    "ratings = []\n",
    "reviews = []\n",
    "\n",
    "# opening each link to begin the scaping\n",
    "for m in all_reviews:\n",
    "    driver.get(m)\n",
    "    time.sleep(15)\n",
    "    \n",
    "    # loop to open link till page 5 and scraping data of reviews and ratings of products\n",
    "    for n in range(0,5):\n",
    "        for o in driver.find_elements_by_xpath(\"//div[@class = 'a-section review aok-relative']/div/div/div[2]/a[1]\"):\n",
    "            ratings.append(o.get_attribute('title').replace(' out of 5 stars',''))\n",
    "            \n",
    "        for p in driver.find_elements_by_xpath(\"//div[@class = 'a-section review aok-relative']/div/div/div[4]/span/span\"):\n",
    "            reviews.append(p.text)\n",
    "                        \n",
    "        try:\n",
    "            next_page = driver.find_element_by_xpath(\"//ul[@class = 'a-pagination']/li[2]/a\")\n",
    "            driver.get(next_page.get_attribute('href'))\n",
    "        except NoSuchElementException as e:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Bought the Mi Ultra laptop during the first sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Pros:\\n1) Build quality.\\n2) Display (best I h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Overall product is good, but charger is missin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Thanks to livetre.com who's reviewing this lap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>You will not get an option to buy extended wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20437</th>\n",
       "      <td>4.0</td>\n",
       "      <td>D-link thought to be made from taiwan but its ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20438</th>\n",
       "      <td>5.0</td>\n",
       "      <td>It did not even connect with PPPoE connection....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20439</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Do not spend your money buying this router. Af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20440</th>\n",
       "      <td>5.0</td>\n",
       "      <td>this is not dual band router, this is working ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20441</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Best dual band router at very low price. Gives...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20442 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Ratings                                        Full_review\n",
       "0         1.0  Bought the Mi Ultra laptop during the first sa...\n",
       "1         5.0  Pros:\\n1) Build quality.\\n2) Display (best I h...\n",
       "2         1.0  Overall product is good, but charger is missin...\n",
       "3         5.0  Thanks to livetre.com who's reviewing this lap...\n",
       "4         1.0   You will not get an option to buy extended wa...\n",
       "...       ...                                                ...\n",
       "20437     4.0  D-link thought to be made from taiwan but its ...\n",
       "20438     5.0  It did not even connect with PPPoE connection....\n",
       "20439     4.0  Do not spend your money buying this router. Af...\n",
       "20440     5.0  this is not dual band router, this is working ...\n",
       "20441     1.0  Best dual band router at very low price. Gives...\n",
       "\n",
       "[20442 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving scraped data into dataframe.\n",
    "search = pd.DataFrame({}) \n",
    "search['Ratings'] = ratings[:20442]\n",
    "search['Full_review'] = reviews[:20442]\n",
    "search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving scraped data in csv format\n",
    "search.to_csv('Ratings_Prediction_Amazon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
