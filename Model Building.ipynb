{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.naive_bayes import ComplementNB, GaussianNB, MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import gensim\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, GlobalMaxPooling1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Full_review</th>\n",
       "      <th>word_count</th>\n",
       "      <th>cleaned_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bought ultra laptop first sale st aug extremel...</td>\n",
       "      <td>391</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>pro build quality display best ever seen among...</td>\n",
       "      <td>65</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>overall product good charger missing package w...</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>thanks livetre com who reviewing laptop right ...</td>\n",
       "      <td>119</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>you get option buy extended warranty buying la...</td>\n",
       "      <td>60</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Ratings                                        Full_review  \\\n",
       "0           0      1.0  bought ultra laptop first sale st aug extremel...   \n",
       "1           1      5.0  pro build quality display best ever seen among...   \n",
       "2           2      1.0  overall product good charger missing package w...   \n",
       "3           3      5.0  thanks livetre com who reviewing laptop right ...   \n",
       "4           4      1.0  you get option buy extended warranty buying la...   \n",
       "\n",
       "   word_count  cleaned_length  \n",
       "0         391             202  \n",
       "1          65              44  \n",
       "2          17              10  \n",
       "3         119              74  \n",
       "4          60              29  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7511 entries, 0 to 7518\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Unnamed: 0      7511 non-null   int64  \n",
      " 1   Ratings         7511 non-null   float64\n",
      " 2   Full_review     7511 non-null   object \n",
      " 3   word_count      7511 non-null   int64  \n",
      " 4   cleaned_length  7511 non-null   int64  \n",
      "dtypes: float64(1), int64(3), object(1)\n",
      "memory usage: 352.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['Full_review']\n",
    "y = df['Ratings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tfidf.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,\n",
    "                                                   y,\n",
    "                                                   test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComplementNB()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = ComplementNB()\n",
    "model1.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[216,  13,   3,   7, 251],\n",
       "       [ 37,   0,   0,   1,  41],\n",
       "       [ 40,   0,   4,   5,  72],\n",
       "       [ 85,   4,   2,   2, 177],\n",
       "       [192,   9,   4,   8, 330]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.38      0.44      0.41       490\n",
      "         2.0       0.00      0.00      0.00        79\n",
      "         3.0       0.31      0.03      0.06       121\n",
      "         4.0       0.09      0.01      0.01       270\n",
      "         5.0       0.38      0.61      0.47       543\n",
      "\n",
      "    accuracy                           0.37      1503\n",
      "   macro avg       0.23      0.22      0.19      1503\n",
      "weighted avg       0.30      0.37      0.31      1503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Score is not good lets try oversampling on data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "os = RandomOverSampler()\n",
    "X_os, y_os = os.fit_resample(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13800, 16542), (13800,), (7511, 16542), (7511,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_os.shape, y_os.shape, x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_os, x_test_os, y_train_os, y_test_os = train_test_split(X_os,\n",
    "                                                   y_os,\n",
    "                                                   test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComplementNB()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = ComplementNB()\n",
    "model2.fit(x_train_os, y_train_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = model2.predict(x_test_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.50      0.36      0.42       561\n",
      "         2.0       0.59      0.89      0.71       541\n",
      "         3.0       0.63      0.81      0.71       531\n",
      "         4.0       0.61      0.62      0.61       561\n",
      "         5.0       0.49      0.24      0.32       566\n",
      "\n",
      "    accuracy                           0.58      2760\n",
      "   macro avg       0.56      0.59      0.56      2760\n",
      "weighted avg       0.56      0.58      0.55      2760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_os, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = MultinomialNB()\n",
    "model4.fit(x_train_os, y_train_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred4 = model4.predict(x_test_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.44      0.39      0.42       561\n",
      "         2.0       0.65      0.83      0.73       541\n",
      "         3.0       0.57      0.78      0.66       531\n",
      "         4.0       0.59      0.55      0.57       561\n",
      "         5.0       0.45      0.24      0.32       566\n",
      "\n",
      "    accuracy                           0.56      2760\n",
      "   macro avg       0.54      0.56      0.54      2760\n",
      "weighted avg       0.54      0.56      0.53      2760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_os, y_pred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5 = RandomForestClassifier()\n",
    "model5.fit(x_train_os, y_train_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred5 = model5.predict(x_test_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.57      0.58      0.58       561\n",
      "         2.0       0.96      1.00      0.98       541\n",
      "         3.0       0.97      0.96      0.97       531\n",
      "         4.0       0.89      0.85      0.87       561\n",
      "         5.0       0.56      0.57      0.56       566\n",
      "\n",
      "    accuracy                           0.79      2760\n",
      "   macro avg       0.79      0.79      0.79      2760\n",
      "weighted avg       0.79      0.79      0.79      2760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_os, y_pred5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hifzu\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:46:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=16, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6 = XGBClassifier()\n",
    "model6.fit(x_train_os, y_train_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred6 = model6.predict(x_test_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.52      0.44      0.48       561\n",
      "         2.0       0.83      0.98      0.90       541\n",
      "         3.0       0.80      0.84      0.82       531\n",
      "         4.0       0.70      0.71      0.71       561\n",
      "         5.0       0.46      0.42      0.44       566\n",
      "\n",
      "    accuracy                           0.67      2760\n",
      "   macro avg       0.66      0.68      0.67      2760\n",
      "weighted avg       0.66      0.67      0.66      2760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_os, y_pred6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'bootstrap': [True, False],\n",
    " 'max_depth': [20,40,50 ],\n",
    " 'max_features': ['auto', 'sqrt'],\n",
    " 'min_samples_leaf': [1, 2, 4],\n",
    " 'min_samples_split': [2, 5, 10],\n",
    " 'n_estimators': [100,200,600]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits = 5, random_state = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_grid = GridSearchCV(RandomForestClassifier(),\n",
    "                       param_grid = params,\n",
    "                       cv = cv,\n",
    "                       verbose = True,\n",
    "                       n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n"
     ]
    }
   ],
   "source": [
    "rfc_grid.fit(x_train_os, y_train_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred7 = rfc_grid.predict(x_test_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_os, y_pred7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(confusion_matrix(y_test_os, y_pred7),\n",
    "           annot = True,\n",
    "           fmt = '4g');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(rfc_grid, 'Ratings-predictor.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
